{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "janela = 4 #tamanho da Janela deslizante\n",
    "\n",
    "problem_name = 'lstm_sales' #to save\n",
    "model_architecture = 'VGG_16'\n",
    "weights_path = None \n",
    "target_size = (224, 224) \n",
    "batch_size = 1\n",
    "\n",
    "epochs = 100 #após x épocas sem melhorar pará (a usar callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math, time\n",
    "import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "# fixar random seed para se puder reproduzir os resultados\n",
    "seed = 9\n",
    "np.random.seed(seed)\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Conv2D, Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.constraints import maxnorm \n",
    "from keras.optimizers import SGD \n",
    "from keras.utils import np_utils \n",
    "from keras import backend as K \n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "import keras\n",
    "K.set_image_dim_ordering('tf') #ordem 'th' ou 'tf' \n",
    "from numpy import genfromtxt\n",
    "import math \n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from time import time as tick\n",
    "import matplotlib.pyplot as plt \n",
    "import pickle \n",
    "from os import listdir\n",
    "from PIL import Image, ImageOps\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "from scipy.misc\timport toimage \n",
    "from scipy import misc, ndimage\n",
    "import scipy.fftpack as pack\n",
    "import scipy.misc\n",
    "from scipy.ndimage import rotate\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pathlib\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#função load_data do lstm.py configurada para aceitar qualquer número de parametros\n",
    "#o último atributo é que fica como label (resultado)\n",
    "#stock é um dataframe do pandas (uma especie de dicionario + matriz)\n",
    "#seq_len é o tamanho da janela a ser utilizada na serie temporal\n",
    "def load_data(df_dados, janela):\n",
    "    qt_atributos = len(df_dados.columns)\n",
    "    mat_dados = df_dados.as_matrix() #converter dataframe para matriz (lista com lista de cada registo)\n",
    "    tam_sequencia = janela + 1\n",
    "    res = []\n",
    "    for i in range(len(mat_dados) - tam_sequencia): #numero de registos - tamanho da sequencia\n",
    "        res.append(mat_dados[i: i + tam_sequencia])\n",
    "    \n",
    "    res = np.array(res) #dá como resultado um np com uma lista de matrizes (janela deslizante ao longo da serie)\n",
    "\n",
    "    #qt_casos_treino = int(round(0.9 * res.shape[0])) #90% passam a ser casos de treino\n",
    "    \n",
    "    qt_casos_treino = 24 # 2 anos\n",
    "    \n",
    "    train = res[:qt_casos_treino, :]\n",
    "    \n",
    "    x_train = train[:, :-1] #menos um registo pois o ultimo registo é o registo a seguir à janela\n",
    "    y_train = train[:, -1][:,-1] #para ir buscar o último atributo para a lista dos labels\n",
    "    x_test = res[qt_casos_treino:, :-1]\n",
    "    y_test = res[qt_casos_treino:, -1][:,-1]\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], qt_atributos))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], qt_atributos))\n",
    "    return [x_train, y_train, x_test, y_test]\n",
    "\n",
    "#imprime um grafico com os valores de teste e com as correspondentes tabela de previsões\n",
    "def print_series_prediction(y_test,predic):\n",
    "    diff=[]\n",
    "    racio=[]\n",
    "    for i in range(len(y_test)): #para imprimir tabela de previsoes\n",
    "        racio.append( (y_test[i]/predic[i])-1)\n",
    "        diff.append( abs(y_test[i]- predic[i]))\n",
    "        print('valor: %f ---> Previsão: %f Diff: %f Racio: %f' % (y_test[i],predic[i], diff[i], racio[i]))\n",
    "    plt.plot(y_test,color='blue', label='y_test')\n",
    "    plt.plot(predic,color='red', label='prediction') #este deu uma linha em branco\n",
    "    plt.plot(diff,color='green', label='diff')\n",
    "    plt.plot(racio,color='yellow', label='racio')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def print_model(model,fich):\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(model, to_file=fich, show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "def print_history_accuracy(history):\n",
    "    print(history.history.keys())\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def print_history_loss(history):\n",
    "    print(history.history.keys())\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
    "\n",
    "def load_batch(fpath, label_key='labels'): \n",
    " \n",
    "    f = open(fpath, 'rb') \n",
    "    d = pickle.load(f, encoding='bytes') \n",
    "    d_decoded = {}        # decode utf8 \n",
    "    for k, v in d.items(): \n",
    "        d_decoded[k.decode('utf8')] = v \n",
    "    d = d_decoded \n",
    "    f.close() \n",
    "    data = d['data'] \n",
    "    labels = d[label_key] \n",
    "    data = data.reshape(data.shape[0], 3, 32, 32) \n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def rotate_resize(temp, tam_image):\n",
    "    #-------------------rodar se necessário e cortar em quadrado\n",
    "    if temp.shape[0] > temp.shape[1]:\n",
    "        temp = rotate(temp,90)\n",
    "    \n",
    "    #cortar em quadrado no centro da imagem e fazer resize para o tam_image\n",
    "    difShapes = temp.shape[1]-temp.shape[0]\n",
    "    return (255 * resize(temp[0:temp.shape[0],int(difShapes/2):int(difShapes/2)+temp.shape[0]],\n",
    "                            (tam_image, tam_image))).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_pre_process():\n",
    "    file_name = 'advertising-and-sales-data-36-co.csv'\n",
    "    col_names = 'date', 'pub', 'sales'\n",
    "    dataset = pd.read_csv(file_name, sep = ';', header=0, names=col_names) #3 colunas\n",
    "    df = pd.DataFrame(dataset)\n",
    "    date_split = df['date'].str.split('-').str\n",
    "    df['year'], df['month'] = date_split #acrescentar ano e mes separados\n",
    "    df.drop(df.columns[[0]], axis=1, inplace=True) #eliminar data original\n",
    "\n",
    "    df = df[:-1] #eliminar a ultima linha porque é uma frase informativa\n",
    "\n",
    "    #vamos passar ano e mes para para strings para não ser interpretado como valores\n",
    "\n",
    "    look_up = {'1': 'First', '2': 'Second', '3': 'Third'}\n",
    "    df['year'] = df['year'].apply(lambda x: look_up[x])\n",
    "\n",
    "    look_up = {'01': 'Jan', '02': 'Feb', '03': 'Mar', '04': 'Apr', '05': 'May',\n",
    "                '06': 'Jun', '07': 'Jul', '08': 'Aug', '09': 'Sep', '10': 'Oct', '11': 'Nov', '12': 'Dec'}\n",
    "\n",
    "    df['month'] = df['month'].apply(lambda x: look_up[x])\n",
    "\n",
    "    df = df[['year', 'month', 'pub', 'sales']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model2(janela, nmr_parametros):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(janela, nmr_parametros), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64, input_shape=(janela, nmr_parametros), return_sequences=False))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.add(Dense(1, activation=\"linear\", kernel_initializer=\"uniform\"))\n",
    "    model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "\n",
    "history_loss = LossHistory() #print(history.losses) to use      \n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, mode='min')    \n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath = 'checkpoint-{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', save_best_only=False, mode='min', period=1)\n",
    "\n",
    "#reduce training rate when no improving\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "\n",
    "csv_logger = CSVLogger('training.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year month   pub  sales\n",
      "0    First   Jan  12.0   15.0\n",
      "1    First   Feb  20.5   16.0\n",
      "2    First   Mar  21.0   18.0\n",
      "3    First   Apr  15.5   27.0\n",
      "4    First   May  15.3   21.0\n",
      "5    First   Jun  23.5   49.0\n",
      "6    First   Jul  24.5   21.0\n",
      "7    First   Aug  21.3   22.0\n",
      "8    First   Sep  23.5   28.0\n",
      "9    First   Oct  28.0   36.0\n",
      "10   First   Nov  24.0   40.0\n",
      "11   First   Dec  15.5    3.0\n",
      "12  Second   Jan  17.3   21.0\n",
      "13  Second   Feb  25.3   29.0\n",
      "14  Second   Mar  25.0   62.0\n",
      "15  Second   Apr  36.5   65.0\n",
      "16  Second   May  36.5   46.0\n",
      "17  Second   Jun  29.6   44.0\n",
      "18  Second   Jul  30.5   33.0\n",
      "19  Second   Aug  28.0   62.0\n",
      "20  Second   Sep  26.0   22.0\n",
      "21  Second   Oct  21.5   12.0\n",
      "22  Second   Nov  19.7   24.0\n",
      "23  Second   Dec  19.0    3.0\n",
      "24   Third   Jan  16.0    5.0\n",
      "25   Third   Feb  20.7   14.0\n",
      "26   Third   Mar  26.5   36.0\n",
      "27   Third   Apr  30.6   40.0\n",
      "28   Third   May  32.3   49.0\n",
      "29   Third   Jun  29.5    7.0\n",
      "30   Third   Jul  28.3   52.0\n",
      "31   Third   Aug  31.3   65.0\n",
      "32   Third   Sep  32.2   17.0\n",
      "33   Third   Oct  26.4    5.0\n",
      "34   Third   Nov  23.4   17.0\n",
      "35   Third   Dec  16.4    1.0\n",
      "X_train (24, 4, 4)\n",
      "y_train (24,)\n",
      "X_test (7, 4, 4)\n",
      "y_test (7,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 4, 128)            68096     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 118,561\n",
      "Trainable params: 118,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 21 samples, validate on 3 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Feb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-e6caba9f776a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjanela\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnmr_parametros\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mtrainScore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1087\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1089\u001b[1;33m             \u001b[0mnp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \"\"\"\n\u001b[1;32m--> 531\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Feb'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    df = read_and_pre_process()\n",
    "    print(df)\n",
    "    X_train, y_train, X_test, y_test = load_data(df[::-1], janela)# o df[::-1] é o df por ordem inversa\n",
    "    \n",
    "    print(\"X_train\", X_train.shape)\n",
    "    print(\"y_train\", y_train.shape)\n",
    "    print(\"X_test\", X_test.shape)\n",
    "    print(\"y_test\", y_test.shape)\n",
    "    \n",
    "    nmr_parametros = X_train.shape[2]\n",
    "    \n",
    "    model = build_model2(janela, nmr_parametros)\n",
    "    print(model.summary())\n",
    "    model.fit(X_train, y_train, batch_size=512, epochs=500, validation_split=0.1, verbose=1)\n",
    "    \n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "    \n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    \n",
    "    print(model.metrics_names)\n",
    "    p = model.predict(X_test)\n",
    "    predic = np.squeeze(np.asarray(p)) #transformar uma matriz de uma coluna e n linhas em um np array de n elementos\n",
    "    print_series_prediction(y_test,predic)\n",
    "    \n",
    "    \n",
    "    ''' \n",
    "    MSE- (Mean square error), RMSE- (root mean square error) –\n",
    "    o significado de RMSE depende do range da label. para o mesmo range menor é melhor.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.0, 21.0, 49.0, 21.0, 27.0, 18.0, 16.0], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['First', 'Dec', 15.5, 3.0],\n",
       "        ['First', 'Nov', 24.0, 40.0],\n",
       "        ['First', 'Oct', 28.0, 36.0],\n",
       "        ['First', 'Sep', 23.5, 28.0]],\n",
       "\n",
       "       [['First', 'Nov', 24.0, 40.0],\n",
       "        ['First', 'Oct', 28.0, 36.0],\n",
       "        ['First', 'Sep', 23.5, 28.0],\n",
       "        ['First', 'Aug', 21.3, 22.0]],\n",
       "\n",
       "       [['First', 'Oct', 28.0, 36.0],\n",
       "        ['First', 'Sep', 23.5, 28.0],\n",
       "        ['First', 'Aug', 21.3, 22.0],\n",
       "        ['First', 'Jul', 24.5, 21.0]],\n",
       "\n",
       "       [['First', 'Sep', 23.5, 28.0],\n",
       "        ['First', 'Aug', 21.3, 22.0],\n",
       "        ['First', 'Jul', 24.5, 21.0],\n",
       "        ['First', 'Jun', 23.5, 49.0]],\n",
       "\n",
       "       [['First', 'Aug', 21.3, 22.0],\n",
       "        ['First', 'Jul', 24.5, 21.0],\n",
       "        ['First', 'Jun', 23.5, 49.0],\n",
       "        ['First', 'May', 15.3, 21.0]],\n",
       "\n",
       "       [['First', 'Jul', 24.5, 21.0],\n",
       "        ['First', 'Jun', 23.5, 49.0],\n",
       "        ['First', 'May', 15.3, 21.0],\n",
       "        ['First', 'Apr', 15.5, 27.0]],\n",
       "\n",
       "       [['First', 'Jun', 23.5, 49.0],\n",
       "        ['First', 'May', 15.3, 21.0],\n",
       "        ['First', 'Apr', 15.5, 27.0],\n",
       "        ['First', 'Mar', 21.0, 18.0]]], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>pub</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First</td>\n",
       "      <td>Jan</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First</td>\n",
       "      <td>Feb</td>\n",
       "      <td>20.5</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First</td>\n",
       "      <td>Mar</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First</td>\n",
       "      <td>Apr</td>\n",
       "      <td>15.5</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First</td>\n",
       "      <td>May</td>\n",
       "      <td>15.3</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>First</td>\n",
       "      <td>Jun</td>\n",
       "      <td>23.5</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>First</td>\n",
       "      <td>Jul</td>\n",
       "      <td>24.5</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>First</td>\n",
       "      <td>Aug</td>\n",
       "      <td>21.3</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>First</td>\n",
       "      <td>Sep</td>\n",
       "      <td>23.5</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>First</td>\n",
       "      <td>Oct</td>\n",
       "      <td>28.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>First</td>\n",
       "      <td>Nov</td>\n",
       "      <td>24.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>First</td>\n",
       "      <td>Dec</td>\n",
       "      <td>15.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Second</td>\n",
       "      <td>Jan</td>\n",
       "      <td>17.3</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Second</td>\n",
       "      <td>Feb</td>\n",
       "      <td>25.3</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Second</td>\n",
       "      <td>Mar</td>\n",
       "      <td>25.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Second</td>\n",
       "      <td>Apr</td>\n",
       "      <td>36.5</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Second</td>\n",
       "      <td>May</td>\n",
       "      <td>36.5</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Second</td>\n",
       "      <td>Jun</td>\n",
       "      <td>29.6</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Second</td>\n",
       "      <td>Jul</td>\n",
       "      <td>30.5</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Second</td>\n",
       "      <td>Aug</td>\n",
       "      <td>28.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Second</td>\n",
       "      <td>Sep</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Second</td>\n",
       "      <td>Oct</td>\n",
       "      <td>21.5</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Second</td>\n",
       "      <td>Nov</td>\n",
       "      <td>19.7</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Second</td>\n",
       "      <td>Dec</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Third</td>\n",
       "      <td>Jan</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Third</td>\n",
       "      <td>Feb</td>\n",
       "      <td>20.7</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Third</td>\n",
       "      <td>Mar</td>\n",
       "      <td>26.5</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Third</td>\n",
       "      <td>Apr</td>\n",
       "      <td>30.6</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Third</td>\n",
       "      <td>May</td>\n",
       "      <td>32.3</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Third</td>\n",
       "      <td>Jun</td>\n",
       "      <td>29.5</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Third</td>\n",
       "      <td>Jul</td>\n",
       "      <td>28.3</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Third</td>\n",
       "      <td>Aug</td>\n",
       "      <td>31.3</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Third</td>\n",
       "      <td>Sep</td>\n",
       "      <td>32.2</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Third</td>\n",
       "      <td>Oct</td>\n",
       "      <td>26.4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Third</td>\n",
       "      <td>Nov</td>\n",
       "      <td>23.4</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Third</td>\n",
       "      <td>Dec</td>\n",
       "      <td>16.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year month   pub  sales\n",
       "0    First   Jan  12.0   15.0\n",
       "1    First   Feb  20.5   16.0\n",
       "2    First   Mar  21.0   18.0\n",
       "3    First   Apr  15.5   27.0\n",
       "4    First   May  15.3   21.0\n",
       "5    First   Jun  23.5   49.0\n",
       "6    First   Jul  24.5   21.0\n",
       "7    First   Aug  21.3   22.0\n",
       "8    First   Sep  23.5   28.0\n",
       "9    First   Oct  28.0   36.0\n",
       "10   First   Nov  24.0   40.0\n",
       "11   First   Dec  15.5    3.0\n",
       "12  Second   Jan  17.3   21.0\n",
       "13  Second   Feb  25.3   29.0\n",
       "14  Second   Mar  25.0   62.0\n",
       "15  Second   Apr  36.5   65.0\n",
       "16  Second   May  36.5   46.0\n",
       "17  Second   Jun  29.6   44.0\n",
       "18  Second   Jul  30.5   33.0\n",
       "19  Second   Aug  28.0   62.0\n",
       "20  Second   Sep  26.0   22.0\n",
       "21  Second   Oct  21.5   12.0\n",
       "22  Second   Nov  19.7   24.0\n",
       "23  Second   Dec  19.0    3.0\n",
       "24   Third   Jan  16.0    5.0\n",
       "25   Third   Feb  20.7   14.0\n",
       "26   Third   Mar  26.5   36.0\n",
       "27   Third   Apr  30.6   40.0\n",
       "28   Third   May  32.3   49.0\n",
       "29   Third   Jun  29.5    7.0\n",
       "30   Third   Jul  28.3   52.0\n",
       "31   Third   Aug  31.3   65.0\n",
       "32   Third   Sep  32.2   17.0\n",
       "33   Third   Oct  26.4    5.0\n",
       "34   Third   Nov  23.4   17.0\n",
       "35   Third   Dec  16.4    1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix + AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(validation_generator.classes, predicted_classes))\n",
    "\n",
    "# AUC for prediction on validation sample\n",
    "X_val_sample, val_labels = next(validation_generator)\n",
    "val_pred = model.predict_proba(X_val_sample)\n",
    "val_pred = np.reshape(val_pred, val_labels.shape)\n",
    "val_score_auc = roc_auc_score(val_labels, val_pred)\n",
    "print (\"AUC validation score: \",val_score_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
